{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from time import perf_counter\n",
    "import psutil\n",
    "import sys\n",
    "import pickle\n",
    "import re\n",
    "import numpy\n",
    "import pefile\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_system_benchmark_inputs():\n",
    "    return (psutil.Process().memory_info().rss / (1024 * 1024)), perf_counter()\n",
    "\n",
    "def print_system_benchmark(before_memory, after_memory, start_time, end_time):\n",
    "    print(\"Memory usaged on extracting features: {0} MB\".format(round(after_memory - before_memory, 4)))\n",
    "    print(\"Elapsed time in seconds: \", round(end_time - start_time, 2))\n",
    "    print(\"=============================================\")\n",
    "\n",
    "# Extract string features of a file\n",
    "def get_features(path, hasher):\n",
    "    features = {}\n",
    "\n",
    "    # Extract PE import functions\n",
    "    try:\n",
    "        pe = pefile.PE(path)\n",
    "        for entry in pe.DIRECTORY_ENTRY_IMPORT:\n",
    "            for function in entry.imports:\n",
    "                try:\n",
    "                    entry_dll = entry.dll.decode(\"ASCII\")\n",
    "                    dll_function = function.name.decode(\"ASCII\")\n",
    "                    feature_function = entry_dll + \":\" + dll_function\n",
    "                    features[feature_function] = 1\n",
    "                except pefile.PEFormatError as err:\n",
    "                    print(\"{0} from '{1}'\".format(err, path))\n",
    "                    continue\n",
    "    except:\n",
    "        print(\"error: failed to acquire directory entry imports from '{0}'\".format(path))\n",
    "    \n",
    "    # Extract strings from executable\n",
    "    chars = r\" -~\"\n",
    "    min_length = 4\n",
    "    string_regexp = '[%s]{%d,}' % (chars, min_length)\n",
    "    file_object = open(path, encoding='cp437')\n",
    "    data = file_object.read()\n",
    "    pattern = re.compile(string_regexp)\n",
    "    strings = pattern.findall(data)\n",
    "    \n",
    "    for string in strings:\n",
    "        features[string] = 1\n",
    "    \n",
    "    return transform_features(features, path, hasher)\n",
    "\n",
    "def transform_features(features, path, hasher):\n",
    "    # Use hashing trick\n",
    "    # Decrease accuracy but improves efficiency for storage and speed\n",
    "    hashed_features = hasher.transform([features])\n",
    "    hashed_features = hashed_features.todense()\n",
    "    hashed_features = numpy.asarray(hashed_features)\n",
    "    hashed_features = hashed_features[0]\n",
    "\n",
    "\n",
    "    print(\"Extracted {0} features from '{1}'\".format(len(features),path))\n",
    "    return hashed_features\n",
    "\n",
    "# Get paths for each executable\n",
    "def get_paths(directory):\n",
    "        targets = []\n",
    "        for path in os.listdir(directory):\n",
    "            targets.append(os.path.join(directory,path))\n",
    "        return targets\n",
    "\n",
    "def get_training_data(benign_path, malicious_path, hasher):\n",
    "    if not os.path.exists(\"research_features.pkl\"):\n",
    "        before_memory_used, start_time = get_system_benchmark_inputs()\n",
    "\n",
    "        malicious_paths = get_paths(malicious_path)\n",
    "        benign_paths = get_paths(benign_path)\n",
    "\n",
    "        print(\"Number of malicious binaries: \", len(malicious_paths))\n",
    "        print(\"Number of benign binaries: \", len(benign_paths))\n",
    "\n",
    "        # Get feature from binaries\n",
    "        X = [get_features(path, hasher) for path in malicious_paths + benign_paths]\n",
    "\n",
    "        # labels of each binaries\n",
    "        y = [1 for i in range(len(malicious_paths))] + [0 for i in range(len(benign_paths))]\n",
    "\n",
    "        after_memory_used, end_time = get_system_benchmark_inputs()\n",
    "        \n",
    "        print(\"==== Extracting features with Feature Hasher benchmarks ====\")\n",
    "        print_system_benchmark(before_memory_used, after_memory_used, start_time, end_time)\n",
    "        with open(\"research_features.pkl\", \"wb\") as save_features:\n",
    "            pickle.dump((X, y), save_features)\n",
    "        return X, y\n",
    "    \n",
    "    with open(\"research_features.pkl\", \"rb\") as saved_features:\n",
    "        X, y = pickle.load(saved_features)\n",
    "    return X, y\n",
    "\n",
    "def train_detector(X, y, hasher):\n",
    "\n",
    "    if not os.path.exists(\"research_saved_random_forest_detector.pkl\"):\n",
    "        classifier = RandomForestClassifier()\n",
    "        classifier.fit(X, y)\n",
    "        with open(\"research_saved_random_forest_detector.pkl\", \"wb\") as save_detector:\n",
    "            pickle.dump((classifier,hasher), save_detector)\n",
    "    \n",
    "    if not os.path.exists(\"research_saved_knn_detector.pkl\"):\n",
    "        classifier = KNeighborsClassifier()\n",
    "        classifier.fit(X, y)\n",
    "        with open(\"research_saved_knn_detector.pkl\", \"wb\") as save_detector:\n",
    "            pickle.dump((classifier,hasher), save_detector)\n",
    "    \n",
    "    if not os.path.exists(\"research_saved_logistic_regression_detector.pkl\"):\n",
    "        classifier = LogisticRegression()\n",
    "        classifier.fit(X, y)\n",
    "        with open(\"research_saved_logistic_regression_detector.pkl\", \"wb\") as save_detector:\n",
    "            pickle.dump((classifier,hasher), save_detector)\n",
    "\n",
    "def scan_file(path, classifier = \"random_forest\", threshold = 0.5):\n",
    "    if classifier == \"random_forest\":\n",
    "        if not os.path.exists(\"research_saved_random_forest_detector.pkl\"):\n",
    "            print(\"Train a detector before scanning files\")\n",
    "            sys.exit(1)\n",
    "        with open(\"research_saved_random_forest_detector.pkl\", \"rb\") as saved_detector:\n",
    "            classifier, hasher = pickle.load(saved_detector)\n",
    "    \n",
    "    if classifier == \"knn\":\n",
    "        if not os.path.exists(\"research_saved_knn_detector.pkl\"):\n",
    "            print(\"Train a detector before scanning files\")\n",
    "            sys.exit(1)\n",
    "        with open(\"research_saved_knn_detector.pkl\", \"rb\") as saved_detector:\n",
    "            classifier, hasher = pickle.load(saved_detector)\n",
    "\n",
    "    if classifier == \"logistic_regression\":\n",
    "        if not os.path.exists(\"research_saved_logistic_regression_detector.pkl\"):\n",
    "            print(\"Train a detector before scanning files\")\n",
    "            sys.exit(1)\n",
    "        with open(\"research_saved_logistic_regression_detector.pkl\", \"rb\") as saved_detector:\n",
    "            classifier, hasher = pickle.load(saved_detector)\n",
    "\n",
    "    features = get_features(path, hasher)\n",
    "\n",
    "    result_prob = classifier.predict_proba([features])[:, -1]\n",
    "\n",
    "    if result_prob > threshold:\n",
    "        print(\"It appears this file is malicious!\",result_prob)\n",
    "        return 1\n",
    "    else:\n",
    "        print (\"It appears this file is benign.\",result_prob)\n",
    "        return 0\n",
    "\n",
    "# Print malware detection performance\n",
    "def print_metrics(y_true, y_pred):\n",
    "    print(\"Accuracy: {:.2f}%\".format(metrics.accuracy_score(y_true, y_pred) * 100))\n",
    "    print(\"Precision: {:.2f}%\".format(metrics.precision_score(y_true, y_pred) * 100))\n",
    "    print(\"F1 score: {:.2f}%\".format(metrics.f1_score(y_true, y_pred) * 100))\n",
    "\n",
    "def evaluate(X, y, classifier = \"random_forest\"):\n",
    "\n",
    "    if classifier == \"random_forest\":\n",
    "        classifier = RandomForestClassifier()\n",
    "    if classifier == \"knn\":\n",
    "        classifier = KNeighborsClassifier()\n",
    "    if classifier == \"logistic_regression\":\n",
    "        classifier = LogisticRegression()\n",
    "\n",
    "    optimal_thresholds = []\n",
    "\n",
    "    X, y = numpy.array(X), numpy.array(y)\n",
    "\n",
    "    # Split training data to use it as test data\n",
    "    \n",
    "    for fold_counter, (train_index, test_index) in enumerate(KFold(n_splits=3, shuffle=True).split(X)):\n",
    "        training_X, training_y = X[train_index], y[train_index]\n",
    "        test_X, test_y = X[test_index], y[test_index]\n",
    "        \n",
    "        classifier.fit(training_X,training_y)\n",
    "        \n",
    "        scores = classifier.predict_proba(test_X)[:, -1]\n",
    "\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(test_y, scores)\n",
    "\n",
    "        optimal_proba_threshold = sorted(list(zip(numpy.abs(tpr - fpr), thresholds)), key=lambda i: i[0], reverse=True)[0][1]\n",
    "\n",
    "        optimal_thresholds.append(optimal_proba_threshold)\n",
    "\n",
    "        roc_predictions = [1 if i >= optimal_proba_threshold else 0 for i in scores]\n",
    "        non_roc_predictions = [1 if i >= 0.5 else 0 for i in scores]\n",
    "\n",
    "        print(\"######Fold {0}######\".format(fold_counter))\n",
    "        print(\"Metrics without ROC\")\n",
    "        print_metrics(test_y, non_roc_predictions)\n",
    "\n",
    "        print(\"\\n\")\n",
    "        print(\"Metrics with ROC\")\n",
    "        print_metrics(test_y, roc_predictions)\n",
    "\n",
    "        print(\"####################\\n\")\n",
    "\n",
    "    # Get average optimal threshold\n",
    "    threshold = 0\n",
    "    for optimal_threshold in optimal_thresholds:\n",
    "        threshold += optimal_threshold\n",
    "    \n",
    "    threshold = threshold / len(optimal_thresholds)\n",
    "    return threshold\n",
    "\n",
    "def run_test_scan(classifier, threshold = 0.5):\n",
    "    # Binaries are from Data Science for malware\n",
    "    # https://www.malwaredatascience.com/code-and-data\n",
    "    test_path = \"./samples/testing_samples/\"\n",
    "    malicious_files_to_scan = get_paths(test_path + \"malware/\")\n",
    "    benign_files_to_scan = get_paths(test_path + \"benignware/\")\n",
    "\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    # Start Benchmark\n",
    "    before_memory_used, start_time = get_system_benchmark_inputs()\n",
    "\n",
    "\n",
    "    # Start scanning\n",
    "    for file_path in malicious_files_to_scan:\n",
    "        y_true.append(1)\n",
    "        y_pred.append(scan_file(file_path, classifier,threshold))\n",
    "\n",
    "    for file_path in benign_files_to_scan:\n",
    "        y_true.append(0)\n",
    "        y_pred.append(scan_file(file_path, classifier,threshold))\n",
    "\n",
    "    # End Benchmark\n",
    "    after_memory_used, end_time = get_system_benchmark_inputs()\n",
    "        \n",
    "    print(\"==== {0} model scanning benchmarks ====\".format(classifier))\n",
    "    print_system_benchmark(before_memory_used, after_memory_used, start_time, end_time)\n",
    "\n",
    "    print(\"Number of malicious samples: \", len(malicious_files_to_scan))\n",
    "    print(\"Number of benign samples: \", len(benign_files_to_scan))\n",
    "    print_metrics(y_true, y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hasher = FeatureHasher(20000)\n",
    "path = \"./samples/training_samples/\"\n",
    "bPath = path + \"benignware/\" # benign path\n",
    "mPath = path + \"malware/\" # malware path\n",
    "X, y = get_training_data(bPath, mPath, hasher)\n",
    "train_detector(X, y, hasher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest without ROC cross validation\n",
    "run_test_scan(\"random_forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate Random Forest\n",
    "optimal_threshold =  evaluate(X, y)\n",
    "# Random Forest with ROC cross validation\n",
    "run_test_scan(\"random_forest\", optimal_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Nearest Neighbors without ROC cross validation\n",
    "run_test_scan(\"knn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate K-Nearest Neighbours\n",
    "optimal_threshold =  evaluate(X, y, \"knn\")\n",
    "# K-Nearest Neighbours with ROC cross validation\n",
    "run_test_scan(\"knn\", optimal_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression without ROC cross validation\n",
    "run_test_scan(\"logistic_regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Logistic Regression\n",
    "optimal_threshold =  evaluate(X, y, \"logistic_regression\")\n",
    "# Linear Regression with ROC cross validation\n",
    "run_test_scan(\"logistic_regression\", optimal_threshold)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
